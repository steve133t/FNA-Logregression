{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<center> <h1> CSE 574 Project 1 </h1> </center>\n",
    "\n",
    "<center> <h2> Authors: Mihir Chauhan, Sargur Srihari </h2> </center>\n",
    "\n",
    "<center> <h2> Due Time and Date: 11:59PM October 7th 2020 </h2> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1 Task\n",
    "\n",
    "The task of this project is to perform classification using machine learning for a two class problem. The features used for classification are pre-computed from images of a fine needle aspirate (FNA) ofa breast mass.  Your task is to classify suspected FNA cells to Benign (class 0) or Malignant (class 1) using logistic regression as the classifier. The dataset in use is the Wisconsin Diagnostic Breast Cancer (wdbc.csv).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "You will be using Wisconsin Diagnostic Breast Cancer (WDBC) dataset for training, validation and testing. The  dataset you are provided with is wdbc.csv  which contains  500  data points with  31  attributes (diagnosis  (B/M),  30  real-valued  inputfeatures). \n",
    "\n",
    "####  How are the 30 features computed? (Below info. is just for your knowledge)\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breastmass.  Computed features describes the following characteristics of the cell nuclei present in the image. \n",
    "\n",
    "|    |                              Feature                              |\n",
    "|----|:-----------------------------------------------------------------:|\n",
    "| 1  | radius (mean of distances from center to points on the perimeter) |\n",
    "| 2  | texture (standard deviation of gray-scale                         |\n",
    "| 3  | perimeter                                                         |\n",
    "| 4  | area                                                              |\n",
    "| 5  | smoothness (local variation in radius lengths)                    |\n",
    "| 6  | compactness (perimeter2/area − 1.0)                               |\n",
    "| 7  | concavity (severity of concave portions of the contour)           |\n",
    "| 8  | concave points (number of concave portions of the contour)        |\n",
    "| 9  | symmetry                                                          |\n",
    "| 10 | fractal dimension (“coastline approximation” - 1)                 |\n",
    "\n",
    "The mean, standard error, and “worst” or largest (mean of the three largest values) of these features were computed for each image, resulting in <b>30 features<b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan of work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: Import Libraries\n",
    "\n",
    "You are NOT ALLOWED to use any libraries for directly implementing Logistic Regression.\n",
    "\n",
    "For eg. [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) <font color='red'>NOT ALLLOWED</font>\n",
    "\n",
    "You need to implement Logistic Regression from scratch using Gradient Descent Optimization Algorithm. \n",
    "\n",
    "You can use libraries for:\n",
    "* loading data (Pandas, Numpy), <font color='green'>ALLLOWED</font>\n",
    "* Preprocessing Data (sklearn > preprocessing), <font color='green'>ALLLOWED</font>\n",
    "* Partitioning Data (sklearns > train_test_split), <font color='green'>ALLLOWED</font>\n",
    "* Plotting Graphs (Matplotlib) <font color='green'>ALLLOWED</font>\n",
    "* Finding Accuracy, Precision, Recall using sklearn.metrics <font color='green'>ALLLOWED</font>\n",
    "\n",
    "You can alternatively use other libraries to implement any sub-task (e.g. loading, partitioning etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt, loadtxt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data Loading <font color='blue'>(5 Points)</font>\n",
    "\n",
    "1. Read 'wdbc.csv' data using Pandas library. Load the data in a dataframe\n",
    "2. Drop first row as it is the header row\n",
    "2. Map Malignant to Class 1 and Benign to Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"data\\wdbc.csv\"\n",
    "\n",
    "# extracting data\n",
    "data = pd.read_csv(path_to_file, encoding='UTF-8',header=None)\n",
    "def data_preprocessor(data=None):\n",
    "    # dropping column 1\n",
    "    data = data.drop([0])\n",
    "\n",
    "    # get row, column count\n",
    "    row_count = data.shape[0]\n",
    "    col_count = data.shape[1]\n",
    "    print(\"No. of rows: \",row_count)\n",
    "    print(\"No. of columns: \",col_count)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "\n",
    "    col_names = []\n",
    "    # col_names = [col_names.append(\"col_\"+str(i+1)) for i in range(col_count)]\n",
    "\n",
    "    # create list of header names\n",
    "    for i in range(col_count):\n",
    "        col_names.append(\"col_\"+str(i+1))\n",
    "    # print(col_names)\n",
    "\n",
    "    # update dataset with header names\n",
    "    data.columns = col_names\n",
    "\n",
    "    # Map label column to 0 and 1. \n",
    "    # 0: B (Benign), 1: M (Malingnant)\n",
    "    data.col_1 = data.col_1.map({'M':1, 'B':0})\n",
    "\n",
    "    # split data in train(80%),validate(10%) and test(10%) dataframes\n",
    "    # get the X,Y where X is training set and Y is target vector.\n",
    "    X_train, X_other, Y_train, Y_other = train_test_split(data.iloc[:,1:], data.col_1, train_size=0.8, random_state=50)\n",
    "    X_validate, X_test, Y_validate, Y_test = train_test_split(X_other,Y_other,train_size=0.5,random_state=50)\n",
    "\n",
    "    return X_train, Y_train, X_validate, Y_validate, X_test, Y_test, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Data Partitioning <font color='blue'>(5 Points)</font>\n",
    "\n",
    "1. Partition your data into training (80%), validation (20%) and testing data(20%) using sklearn library (Hint: use train_test_split)\n",
    "2. Seperate Target Label (y) and Features (x1 to x30) for training, validation and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done in function above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Scaling Features <font color='blue'>(5 Points)</font>\n",
    "\n",
    "One simple scaling function that you could use off the shelf is Min Max Scaler function of Sklearns. Min Max scaler function transforms features by scaling each feature to a range between <b> 0 and 1 </b>. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\n",
    "\n",
    "The transformation is given by:\n",
    "\n",
    "$X_{std} = \\frac{X - X_{min}}{X_{max} - X_{min}}$\n",
    "\n",
    "$X_{scaled} = X_{std} * (maxRange - minRange) + minRange$\n",
    "\n",
    "$maxRange$ = 1, <br>\n",
    "$minRange$ = 0, <br>\n",
    "$X_{max}$ and $X_{min}$ are over axis = 0 (Each columns max and min value) \n",
    "\n",
    "##### Why do we need to scale features?\n",
    "We scale the data to bring all the features to the same range (in our case between 0 and 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint, make sure the dimensionality of the training features, weights, biases are consistent for np.dot and np.multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(matrix=None,name=None):\n",
    "    if type(matrix) is list:\n",
    "        for m in range(len(matrix)):\n",
    "            print(\"Shape of {}:        \\t\".format(name[m]),matrix[m].shape)\n",
    "    else:\n",
    "        print(\"Shape of {}:        \\t\".format(name),matrix.shape)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    \n",
    "def normalize(X_train=None, Y_train=None, X_validate=None, Y_validate=None, X_test=None, Y_test=None):\n",
    "    # normalize the feature set\n",
    "    scaler_obj = StandardScaler()\n",
    "    scaler_obj.fit(X_train)\n",
    "    mean_val = scaler_obj.mean_\n",
    "    # print(mean_val)\n",
    "    X_train = scaler_obj.transform(X_train)\n",
    "    X_validate = scaler_obj.transform(X_validate)\n",
    "    X_test = scaler_obj.transform(X_test)\n",
    "\n",
    "    # Converting Y into array values (did this to fix Y datas and make them into a vector)\n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_validate = np.array(Y_validate)\n",
    "    Y_test = np.array(Y_test)\n",
    "        \n",
    "    # reshaping Y target vectors from (x,) to (x,1)\n",
    "    Y_train = Y_train.reshape(400,1)\n",
    "    Y_validate = Y_validate.reshape(50,1)\n",
    "    Y_test = Y_test.reshape(50,1)\n",
    "    \n",
    "    return X_train, Y_train, X_validate, Y_validate, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Initialization of Variables\n",
    "* Initialize Hyper-Parameters (Learning Rate, Number of Epochs) to some value\n",
    "* Initialize weights to any random values (We have initialized weights as an array random values sampled from a normal distribution)\n",
    "* Initialize bias to any scalar value (We have initialized bias to value 0)\n",
    "* Initialize other variables which may be used for tracking cost, number of data points etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(hp_flag=False):\n",
    "    # initialize weights with 0\n",
    "    weights = np.zeros((30,1), dtype=np.int64)\n",
    "#     print(weights)\n",
    "#     print(len(weights))\n",
    "\n",
    "    # initialize bias with 0\n",
    "    bias = 0\n",
    "\n",
    "    if hp_flag:\n",
    "        # set learning rate to \n",
    "        learning_rate = [0.1, 0.01, 0.003, 0.005, 0.0001]\n",
    "    else:\n",
    "        # set learning rate to \n",
    "        learning_rate = 0.003\n",
    "    \n",
    "    print(\"Learning rate(s)\", learning_rate)\n",
    "\n",
    "    return weights, bias, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: TRAINING with Logistic Regression Implementation using Gradient Descent Algorithm <font color='blue'>(30 Points)</font>\n",
    "\n",
    "Iteratively update the weights and biases for each epoch using:\n",
    "* Step 6.1: Use genesis equation $\\hat{y} = \\sigma (W.X + b)$ where $W$ is the weight array, $X$ is the input features and $\\hat{y}$ is the predicted value which will be between 0 and 1. (You will have to perform same operation on validation set as well)\n",
    "* Step 6.2: Find Binary Cross Entropy Cost for training and validation set using predicted value $\\hat{y}$ and truth value $y$\n",
    "* Step 6.3: Find $ \\Delta W = \\frac{\\delta L}{\\delta W}$ and $ \\Delta b = \\frac{\\delta L}{\\delta b}$ (Proof for finding  $ \\Delta W$ and $\\Delta b$ is available in prof. slides)\n",
    "* Step 6.4: Update $W$ and $b$ using learning rate as follows:\n",
    "  - $W = W - learningRate*\\Delta W$\n",
    "  - $b = b - learningRate*\\Delta b$\n",
    "* Step 6.5: Store BCE Cost for training and validation in seperate cost tracking list\n",
    "* Step 6.6: Calculate Training and Validation Accuracy and store in seperate accuracy tracking list (<b>Hint</b>: Threshold $\\hat{y}$ to 0.5 for category determination for finding accuracy)\n",
    "\n",
    "Run step 6 multiple times, each time with a different set of hyperparameters and determine the best set of hyperparameters which gives best training and validation accuracy. \n",
    "\n",
    "Corresponding to the best set of hyper parameters, you should get the best set of weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows:  500\n",
      "No. of columns:  31\n",
      "------------------------------------------------------------------------\n",
      "Data is normalized!\n",
      "Printing Matrix dimensions of all sets\n",
      "Shape of X_train:        \t (400, 30)\n",
      "Shape of Y_train:        \t (400, 1)\n",
      "Shape of X_validate:        \t (50, 30)\n",
      "Shape of Y_validate:        \t (50, 1)\n",
      "Shape of X_test:        \t (50, 30)\n",
      "Shape of Y_test:        \t (50, 1)\n",
      "------------------------------------------------------------------------\n",
      "Learning rate(s) 0.003\n",
      "Shape of weights:        \t (30, 1)\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Learning Rate:  0.003\n",
      "Shape of z:        \t (1, 400)\n",
      "Shape of activation:        \t (1, 400)\n",
      "Shape of Y_train:        \t (1, 400)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Train Loss Value[0]:  \t 0.6931471805599452\n",
      "Shape of z_valid:        \t (1, 50)\n",
      "Shape of activation_valid:        \t (1, 50)\n",
      "Shape of Y_validate:        \t (1, 50)\n",
      "------------------------------------------------------------------------\n",
      "Validate Loss Value[0]:  \t 0.6931471805599453\n",
      "\n",
      "\n",
      "Train Loss Value[1000]:  \t 0.1651745268559061\n",
      "Validate Loss Value[1000]:  \t 0.14822685253466827\n",
      "\n",
      "\n",
      "Train Loss Value[2000]:  \t 0.12682493554094895\n",
      "Validate Loss Value[2000]:  \t 0.10826075507642997\n",
      "\n",
      "\n",
      "Train Loss Value[3000]:  \t 0.11053731751285202\n",
      "Validate Loss Value[3000]:  \t 0.0894621055086841\n",
      "\n",
      "\n",
      "Train Loss Value[4000]:  \t 0.1011403390994587\n",
      "Validate Loss Value[4000]:  \t 0.07787320562514802\n",
      "\n",
      "\n",
      "Train Loss Value[5000]:  \t 0.0948846142423752\n",
      "Validate Loss Value[5000]:  \t 0.06982086612451693\n",
      "\n",
      "\n",
      "Train Loss Value[6000]:  \t 0.09035520398395011\n",
      "Validate Loss Value[6000]:  \t 0.0638285746613997\n",
      "\n",
      "\n",
      "Train Loss Value[7000]:  \t 0.0868884430642998\n",
      "Validate Loss Value[7000]:  \t 0.059163212483443736\n",
      "\n",
      "\n",
      "Train Loss Value[8000]:  \t 0.08412802206674684\n",
      "Validate Loss Value[8000]:  \t 0.05541135449904188\n",
      "\n",
      "\n",
      "Train Loss Value[9000]:  \t 0.08186400879115147\n",
      "Validate Loss Value[9000]:  \t 0.052319086582903164\n",
      "------------------------------------------------------------------------\n",
      "Cross Entropy Loss vs Epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training accuracy vs Epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "weights (30, 1) \t Bias -0.6703711082942775\n",
      "Training Accuracy: 98.50%\n",
      "Training Precision: 99.24%\n",
      "Training Recall: 96.32%\n",
      "Validation Accuracy: 100.00%\n",
      "Validation Precision: 100.00%\n",
      "Validation Recall: 100.00%\n",
      "Shape of z_test:        \t (1, 50)\n",
      "Shape of activation_test:        \t (1, 50)\n",
      "Shape of Y_test:        \t (1, 50)\n",
      "------------------------------------------------------------------------\n",
      "Test Accuracy: 98.00%\n",
      "Test Precision: 100.00%\n",
      "Test Recall: 95.24%\n"
     ]
    }
   ],
   "source": [
    "def sigmoid_function(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "# function to calculate cross entropy\n",
    "def cross_entropy_function(y,a):\n",
    "    numerator = np.sum(y*np.log(a) + (1-y)*np.log(1-a))\n",
    "    denominator = -y.shape[1]\n",
    "    loss = numerator/denominator\n",
    "    return loss\n",
    "\n",
    "# function to calculate dw weights\n",
    "def calculate_dw(X,Y,a):\n",
    "    # print(\"Before calculating derivative of loss function w.r.t weights\")\n",
    "    # print_shape(matrix=[X,Y,a], name=['X_train','Y','a'])\n",
    "    dw = np.dot(Y-a,X)/-Y.shape[1]\n",
    "    # print_shape(matrix=dw,name='dw')\n",
    "    return dw\n",
    "\n",
    "# function to calculate db bias\n",
    "def calculate_db(Y,a):\n",
    "    # print(\"Before calculating derivative of loss function w.r.t bias\")\n",
    "    # print_shape(matrix=[Y,a], name=['Y','a'])\n",
    "    db = np.sum(Y-a)/-Y.shape[1]\n",
    "    return db\n",
    "\n",
    "# function to classify activation\n",
    "def classify_activation(a):\n",
    "    return [1 if i >= 0.5 else 0 for i in a[0]]\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To produce the graph of Loss vs Epoch for different hyperparameters,\n",
    "set hp_flag (hyperparameter flag) to 'True'.\n",
    "Default value of hp_flag is False. Flag is initialized in the last cell of jupyter notebook.\n",
    "\"\"\"\n",
    "\n",
    "# function to perform logistic regression for different hyperparameters\n",
    "def hyperparameter(X_train=None, Y_train=None, weights=None,bias=None,learning_rate=None):\n",
    "    \n",
    "    # loss tracker\n",
    "    all_losses = []\n",
    "    \n",
    "    # dictionary to store data\n",
    "    regression_values = {}\n",
    "    \n",
    "    for i, rates in enumerate(learning_rate):\n",
    "        # counter\n",
    "        count = 0\n",
    "    \n",
    "        losses = []\n",
    "        \n",
    "        # re-initializing weights and bias to 0, since iterating over new learning rate\n",
    "        weights = np.zeros((30,1), dtype=np.int64)\n",
    "        bias = 0\n",
    "        \n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(\"\\nLearning Rate: \", rates)\n",
    "        \n",
    "        # beginning epoch loop\n",
    "        for epoch in range(10000):\n",
    "\n",
    "            \"\"\"\n",
    "            Performing forward pass for Training data.\n",
    "            Here we calculate:\n",
    "            X_train: The training set with 455 samples and 30 feature set\n",
    "            Y_train: The target vector with 455 targets\n",
    "            z: \n",
    "            activation: The activation or the prediction\n",
    "            losses: The loss tracker for training data. This is a list.\n",
    "            weights: \n",
    "            bias: \n",
    "            \"\"\"\n",
    "            # using the genesis function z=mx+c for training data\n",
    "            z = np.dot(np.transpose(weights),np.transpose(X_train)) + bias\n",
    "\n",
    "            # calculating activation/prediction for training data\n",
    "            activation = sigmoid_function(z)\n",
    "\n",
    "            # changing the shape of Y_train from (455,1) to (1,455) for ease of calculation\n",
    "            Y_train = Y_train.reshape(1,400)\n",
    "\n",
    "            # printing shape of z, activation and Y_train only once\n",
    "            if count == 0:\n",
    "                print_shape(matrix=[z,activation,Y_train],name=['z','activation','Y_train'])\n",
    "\n",
    "            # classify activation in 0 and 1 for training data\n",
    "            \"\"\"\n",
    "            if activation >= 0.5, classify 1\n",
    "            if activation < 0.5, classify 0\n",
    "            \"\"\"  \n",
    "\n",
    "\n",
    "            # calculate cross entropy and keep track of loss for training data\n",
    "            losses.append(cross_entropy_function(Y_train,activation))\n",
    "\n",
    "            # printing value of loss for every 1000 epochs\n",
    "            if epoch%1000 == 0:\n",
    "                print(\"\\n\\nTrain Loss Value[{}]:  \\t\".format(epoch), losses[count])\n",
    "\n",
    "            # increasing counter value after performing forward pass for training\n",
    "            count = count + 1\n",
    "\n",
    "            \"\"\"\n",
    "            Performing backward pass for Training data.\n",
    "            Here we calculate:\n",
    "            weights: \n",
    "            bias: \n",
    "            \"\"\"\n",
    "\n",
    "            # update weightss and bias for training data\n",
    "            weights = np.transpose(weights) - rates * calculate_dw(X_train,Y_train,activation)\n",
    "            bias = bias - rates * calculate_db(Y_train,activation)\n",
    "\n",
    "            # reshaping weights since weights transpose is used during calculation of z\n",
    "            weights = weights.reshape(30,1)\n",
    "            #break\n",
    "        all_losses.append(losses)\n",
    "    \n",
    "    plt.figure(figsize= (10,8))\n",
    "    for x,val in enumerate(all_losses):\n",
    "        plt.plot(np.arange(len(all_losses[x])), all_losses[x], label='Training Loss Track')\n",
    "    plt.legend(learning_rate, loc='upper right')\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Cross Entropy Loss vs Epochs\")\n",
    "    plt.ylabel('Cross Entropy Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    # update dictionary with required values\n",
    "    regression_values.update({'weights':weights, 'bias':bias})\n",
    "    \n",
    "    return regression_values\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# function to perform logistic regression\n",
    "def logistic_regression(X_train=None, Y_train=None, X_validate=None, Y_validate=None, X_test=None, \n",
    "                        Y_test=None, weights=None,bias=None,learning_rate=None):\n",
    "    # counter\n",
    "    count = 0\n",
    "    \n",
    "    # loss tracker\n",
    "    losses = []\n",
    "    vlosses = []\n",
    "    \n",
    "    # decision boundary\n",
    "    training_accuracy = []\n",
    "    validation_accuracy = []\n",
    "    \n",
    "    # dictionary to store data\n",
    "    regression_values = {}\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"\\nLearning Rate: \", learning_rate)\n",
    "    \n",
    "    # beginning epoch loop\n",
    "    for epoch in range(10000):\n",
    "        \n",
    "        \"\"\"\n",
    "        Performing forward pass for Training data.\n",
    "        Here we calculate:\n",
    "        X_train: The training set with 455 samples and 30 feature set\n",
    "        Y_train: The target vector with 455 targets\n",
    "        z: \n",
    "        activation: The activation or the prediction\n",
    "        losses: The loss tracker for training data. This is a list.\n",
    "        weights: \n",
    "        bias: \n",
    "        \n",
    "        \"\"\"\n",
    "        # using the genesis function z=mx+c for training data\n",
    "        z = np.dot(np.transpose(weights),np.transpose(X_train)) + bias\n",
    "        \n",
    "        # calculating activation/prediction for training data\n",
    "        activation = sigmoid_function(z)\n",
    "        \n",
    "        # changing the shape of Y_train from (455,1) to (1,455) for ease of calculation\n",
    "        Y_train = Y_train.reshape(1,400)\n",
    "\n",
    "        # printing shape of z, activation and Y_train only once\n",
    "        if count == 0:\n",
    "            print_shape(matrix=[z,activation,Y_train],name=['z','activation','Y_train'])\n",
    "            \n",
    "        # classify activation in 0 and 1 for training data\n",
    "        \"\"\"\n",
    "        if activation >= 0.5, classify 1\n",
    "        if activation < 0.5, classify 0\n",
    "        \"\"\"  \n",
    "        # calculating training data accuracy\n",
    "        training_accuracy.append(accuracy_score(Y_train[0],classify_activation(activation)))\n",
    "\n",
    "        \n",
    "        # calculate cross entropy and keep track of loss for training data\n",
    "        losses.append(cross_entropy_function(Y_train,activation))\n",
    "        \n",
    "        # printing value of loss for every 1000 epochs\n",
    "        if epoch%1000 == 0:\n",
    "            print(\"\\n\\nTrain Loss Value[{}]:  \\t\".format(epoch), losses[count])\n",
    "        \n",
    "        \"\"\"\n",
    "        Performing forward pass for Validation data.\n",
    "        Here we calculate:\n",
    "        X_validation: The validation set with 57 samples and 30 feature set\n",
    "        Y_validation: The target vector with 57 targets\n",
    "        z_valid: \n",
    "        activation_valid: The activation or the prediction\n",
    "        vlosses: The loss tracker for validation data. This is a list.\n",
    "        vweights: \n",
    "        vbias: \n",
    "        \n",
    "        \"\"\"\n",
    "            \n",
    "        # using the genesis function z=mx+c for validation data\n",
    "        z_valid = np.dot(np.transpose(weights),np.transpose(X_validate)) + bias\n",
    "        \n",
    "        # calculating activation/prediction for validation data\n",
    "        activation_valid = sigmoid_function(z_valid)\n",
    "        \n",
    "        # changing the shape of Y_validate from (455,1) to (1,455) for ease of calculation\n",
    "        Y_validate = Y_validate.reshape(1,50)\n",
    "        \n",
    "        \n",
    "        # printing shape of z_valid, activation_valid and Y_validate only once\n",
    "        if count == 0:\n",
    "            print_shape(matrix=[z_valid,activation_valid,Y_validate],name=['z_valid','activation_valid','Y_validate'])\n",
    "        \n",
    "        # classify activation in 0 and 1 for validation data\n",
    "        \"\"\"\n",
    "        if activation >= 0.5, classify 1\n",
    "        if activation < 0.5, classify 0\n",
    "        \"\"\"        \n",
    "        # calculating validation data accuracy\n",
    "        validation_accuracy.append(accuracy_score(Y_validate[0],classify_activation(activation_valid)))\n",
    "\n",
    "        \n",
    "        # calculate cross entropy and keep track of loss for validation data\n",
    "        vlosses.append(cross_entropy_function(Y_validate,activation_valid))\n",
    "        \n",
    "        # printing value of loss for every 1000 epochs\n",
    "        if epoch%1000 == 0:\n",
    "            print(\"Validate Loss Value[{}]:  \\t\".format(epoch), vlosses[count])\n",
    "        \n",
    "        # increasing counter value after performing forward pass for both training and validation data\n",
    "        count = count + 1\n",
    "        \n",
    "        \"\"\"\n",
    "        Performing backward pass for Training data.\n",
    "        Here we calculate:\n",
    "        weights: \n",
    "        bias: \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # update weightss and bias for training data\n",
    "        weights = np.transpose(weights) - learning_rate * calculate_dw(X_train,Y_train,activation)\n",
    "        bias = bias - learning_rate * calculate_db(Y_train,activation)\n",
    "        \n",
    "        # reshaping weights since weights transpose is used during calculation of z\n",
    "        weights = weights.reshape(30,1)\n",
    "        #break\n",
    "    \n",
    "    # calculate precision and recall for training data\n",
    "    training_precision = precision_score(Y_train[0],classify_activation(activation))\n",
    "    training_recall = recall_score(Y_train[0],classify_activation(activation))\n",
    "\n",
    "    \n",
    "    # calculate precision and recall for validation data\n",
    "    validation_precision = precision_score(Y_validate[0],classify_activation(activation_valid))\n",
    "    validation_recall = recall_score(Y_validate[0],classify_activation(activation_valid))\n",
    "   \n",
    "    \n",
    "    plt.figure(figsize= (10,8))\n",
    "    plt.plot(losses, '-g', label='Training Loss Track')\n",
    "    plt.plot(vlosses, '-b', label='Validation Loss Track')\n",
    "    plt.legend(loc='upper right')\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Cross Entropy Loss vs Epochs\")\n",
    "    plt.ylabel('Cross Entropy Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Training accuracy vs Epochs\")\n",
    "    plt.figure(figsize= (10,8))\n",
    "    plt.plot(training_accuracy, label='Training Accuracy')\n",
    "    plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    # update dictionary with required values\n",
    "    \n",
    "    regression_values.update({'weights':weights, 'bias':bias, 'training_accuracy': training_accuracy, \n",
    "                              'training_precision': training_precision, 'training_recall': training_recall, \n",
    "                              'validation_accuracy': validation_accuracy, 'validation_precision': validation_precision, \n",
    "                              'validation_recall': validation_recall})\n",
    "    \n",
    "    return regression_values\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# function to test model based on testing data\n",
    "def test_model(weights=None,bias=None,X_test=None,Y_test=None):\n",
    "    \n",
    "    # using the genesis function z=mx+c for testing data\n",
    "    z_test = np.dot(np.transpose(weights),np.transpose(X_test)) + bias\n",
    "\n",
    "    # calculating activation/prediction for testing data\n",
    "    activation_test = sigmoid_function(z_test)\n",
    "    \n",
    "    # changing the shape of Y_test from (57,1) to (1,57) for ease of calculation\n",
    "    Y_test = Y_test.reshape(1,50)\n",
    "    \n",
    "    # printing shape of z_test, activation_test and Y_test\n",
    "    print_shape(matrix=[z_test,activation_test,Y_test],name=['z_test','activation_test','Y_test'])\n",
    "    \n",
    "    # calculating testing data accuracy, precision and recall\n",
    "    testing_accuracy = accuracy_score(Y_test[0],classify_activation(activation_test))\n",
    "    testing_precision = precision_score(Y_test[0],classify_activation(activation_test))\n",
    "    testing_recall = recall_score(Y_test[0],classify_activation(activation_test))\n",
    "    \n",
    "    return testing_accuracy, testing_precision, testing_recall\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# set hyperparameter flag to True to view loss against hyperparameters, else default value is False.\n",
    "hp_flag = False\n",
    "\n",
    "# calling data_preprocessor function\n",
    "X_train, Y_train, X_validate, Y_validate, X_test, Y_test, data = data_preprocessor(data=data)\n",
    "\n",
    "# calling normalize function\n",
    "X_train, Y_train, X_validate, Y_validate, X_test, Y_test, = normalize(X_train=X_train, Y_train=Y_train, X_validate=X_validate, \n",
    "                                                                      Y_validate=Y_validate, X_test=X_test, Y_test=Y_test)\n",
    "print(\"Data is normalized!\")\n",
    "print(\"Printing Matrix dimensions of all sets\")\n",
    "print_shape(matrix=[X_train, Y_train, X_validate, Y_validate, X_test, Y_test],\n",
    "            name=['X_train','Y_train','X_validate','Y_validate','X_test','Y_test'])\n",
    "\n",
    "# calling initializer function\n",
    "weights, bias, learning_rate = initializer(hp_flag=hp_flag)\n",
    "print_shape(matrix=weights,name='weights')\n",
    "\n",
    "if hp_flag:\n",
    "    # calling hyperparameter function\n",
    "    regression_values = hyperparameter(X_train=X_train, Y_train=Y_train, weights=weights, bias=bias, \n",
    "                                           learning_rate=learning_rate)\n",
    "else:\n",
    "    # calling logistic_regression function\n",
    "    regression_values = logistic_regression(X_train=X_train, Y_train=Y_train, X_validate=X_validate,\n",
    "                                        Y_validate=Y_validate, X_test=X_test, Y_test=Y_test, weights=weights,\n",
    "                                        bias=bias,learning_rate=learning_rate)\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"weights {0} \\t Bias {1}\".format(regression_values['weights'].shape,regression_values['bias']))\n",
    "    print(\"Training Accuracy: {:0.2f}%\".format(regression_values['training_accuracy'][-1]*100))\n",
    "    print(\"Training Precision: {:0.2f}%\".format(regression_values['training_precision']*100))\n",
    "    print(\"Training Recall: {:0.2f}%\".format(regression_values['training_recall']*100))\n",
    "    print(\"Validation Accuracy: {:0.2f}%\".format(regression_values['validation_accuracy'][-1]*100))\n",
    "    print(\"Validation Precision: {:0.2f}%\".format(regression_values['validation_precision']*100))\n",
    "    print(\"Validation Recall: {:0.2f}%\".format(regression_values['validation_recall']*100))\n",
    "\n",
    "    # calling test model function\n",
    "    accuracy, precision, recall = test_model(weights=regression_values['weights'],bias=regression_values['bias'],X_test=X_test,Y_test=Y_test)\n",
    "    print(\"Test Accuracy: {:0.2f}%\".format(accuracy*100))\n",
    "    print(\"Test Precision: {:0.2f}%\".format(precision*100))\n",
    "    print(\"Test Recall: {:0.2f}%\".format(recall*100))\n",
    "    weights=regression_values['weights']\n",
    "    bias=regression_values['bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing all the steps above, the best set of updated weights and bias should be stored as a <i>weights_biases.csv</i> file. Your <i>weights_biases.csv</i> will tested on a hidden test set and you would be graded on how well your model (weights) performed on this hidden set <font color='blue'>(30 Points)</font>\n",
    "\n",
    "<b>(Do not change the code provided in the cell below for storing the weights and bias)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and Bias consistent :) \n"
     ]
    }
   ],
   "source": [
    "# Save the weights file (DO NOT CHANGE THIS CODE)\n",
    "weights_bias = np.append(weights,bias)\n",
    "\n",
    "if weights_bias.shape == (31,):\n",
    "    print(\"Weights and Bias consistent :) \")\n",
    "\n",
    "    savetxt('weights_bias.csv', weights_bias, delimiter=',')\n",
    "else:\n",
    "    print(\"Weights and Bias inconsistent :( \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Plot Training and Validation Cost vs Number of Epochs <font color='blue'>(5 Points)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#done in step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 8: Plot Training and Validation Accuracy vs Number of Epochs <font color='blue'>(5 Points)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of z_test:        \t (1, 50)\n",
      "Shape of activation_test:        \t (1, 50)\n",
      "Shape of Y_test:        \t (1, 50)\n",
      "------------------------------------------------------------------------\n",
      "Test Accuracy: 98.00%\n",
      "Test Precision: 100.00%\n",
      "Test Recall: 95.24%\n"
     ]
    }
   ],
   "source": [
    "#done in step 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Test your model using tesing data <font color='blue'>(15 Points)</font>\n",
    "\n",
    "* Step 9.1: Use genesis equation $\\hat{y} = \\sigma (W.X_{test} + b)$ where $W$ is the weight array, $X_{test}$ is the input test features and $\\hat{y}$ is the predicted value which will be between 0 and 1.\n",
    "* Step 9.2: Threshold $\\hat{y}$ at 0.5 to find the category for each data point.\n",
    "* Step 9.3: Find accuracy, precision and recall for testing data (you can use sklearns.metrics library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of z_test:        \t (1, 50)\n",
      "Shape of activation_test:        \t (1, 50)\n",
      "Shape of Y_test:        \t (1, 50)\n",
      "------------------------------------------------------------------------\n",
      "Test Accuracy: 98.00%\n",
      "Test Precision: 100.00%\n",
      "Test Recall: 95.24%\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = test_model(weights=regression_values['weights'],bias=regression_values['bias'],X_test=X_test,Y_test=Y_test)\n",
    "print(\"Test Accuracy: {:0.2f}%\".format(accuracy*100))\n",
    "print(\"Test Precision: {:0.2f}%\".format(precision*100))\n",
    "print(\"Test Recall: {:0.2f}%\".format(recall*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Submission to timberlake server\n",
    "\n",
    "* The code for your implementation should be in this Python notebook with necessary comments within the code.\n",
    "\n",
    "* Your <b> Python Code file </b> `main.ipynb`, <b> Data File </b> `wdbc.csv` and your <b>Trained Weights and Bias File</b> `weights_bias.csv`</b> should be put in a single folder named as `proj1code`. \n",
    "\n",
    "* `proj1code` folder should be zipped with the resulting zip file name as `proj1code.zip`.\n",
    "\n",
    "* Submit the Python code on CSE timberlake server with the following script:\n",
    "\n",
    " - `submit_cse474 proj1code.zip` for undergraduates\n",
    " - `submit_cse574 proj1code.zip` for graduates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Rubric\n",
    "* <b>30 Points:</b> Your trained `weights_bias.csv` will be automatically graded using a script on unbiased hidden test data file. Hence, it is important that your `weights_biases` should of dimensionality (31,) and properly trained.\n",
    "* <b>30 Points:</b> Training logic for implementing logistic regression (Step 6)\n",
    "* <b>15 Points:</b> Testing Accuracy, Precision and Recall (Step 9)\n",
    "* <b>5 Points:</b> Plot of Training and Validation cost vs No. of epochs (Step 7) \n",
    "* <b>5 Points:</b> Plot of Training and Validation accuracy vs No. of epochs (Step 8)\n",
    "* <b> 5 points: </b> Scaling features (Step 4)\n",
    "* <b> 5 points: </b> Partitioning Data (Step 3)\n",
    "* <b> 5 points: </b> Data loading (Step 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
